\documentclass[ebook,12pt,oneside,openany]{memoir}
\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage{url}
\usepackage{titlesec}
\usepackage{lettrine}

% for placeholder text
\usepackage{lipsum}

\title{Theology of ML}
\author{Asad Hasan (Alex) \\ Theoretical Computational Scientist}

% Remove the generated chapter title
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries}{}{0pt}{\Huge}
\titlespacing*{\chapter}{0pt}{-50pt}{40pt}

\begin{document}
\makeatletter
\renewcommand{\@date}{} % Remove the definition of \@date
\makeatother
\maketitle
\chapter*{Preface}
\vspace*{\fill} % Vertical space at the top\makebox[\textwidth][c]{%  \parbox{0.8\textwidth}{%    % First line
    \centering    "Command muck with English." \\    % Vertical space in the middle    \vspace{1cm} \\    % Center aligned line    \centering    "Automaton is muck." \\  }%}\vspace*{\fill} % Vertical space at the bottom
\chapter*{Foreword}
I am a machine learning enthusiast and evangelist, who started their software engineering career at the age of sixteen, now aged thirty-three. I work on projects in the machine learning and deterministic computation domains. What prompted me to write this book was how I myself struggled with knowledge transfer as a learning technique, but over time gradually became better at it, by performing cross knowledge domain learning, and working as a generalist with specialists. This book draws inspiration from theological reasoning and draws parallel with dimensional linearizability related analogs.

This work was created with the help of machine learning.
\chapter*{Chapter 1: Theology of Integrity}
\lettrine[lines=2]{\fontsize{48}{56}\selectfont\textbf{T}}{he} construct of a primate society can be perceived as a biological neural network intricately conjugated through communication which can be seen as cultural evolution. Just as artificial neural networks process information, human beings sample the entropy of their surrounding stimuli. This gives way to a balance where the hygiene of such stimuli leads to mutual survival. Integrity in such a microcosm is the responsibility of creating healthy stimuli for the ecosystem one resides in.
The health of the shared cultural evolution which comprises of stimuli, humans are exposed to, is then, determined by epigenetic harmonics and information. Epigenetic harmonics are less of our control, as we react to them, create vaccines to curb plagues induced by them, and learn more about them through discovery. However, information and the automatons made to process information, are what we are to care for to enable the wellbeing of the cultural evolution we live within.
Integrity, as a faith, could be seen as the imprint of God unto stimuli. Many attribute the idea of God to the recent exponential growth in innovation, minus Moore’s law. Ones who wield a useful automaton, control the stratify-able economic utility correlated to it, and it is the choosing of the owner of the said intellectual property to either share its benefits or not. Given that philanthropy is one's own right, but it is not incumbent upon those who own intellectual property to furnish it.
The longevity of a specimen in such a predicament, comes down to the mutual respect for ownership of property and the freedom of those who choose to share their intellectual property for the mutual wellbeing of the species.
	The law reasons in such a manner to exclude individual biases to foster the longevity of individuals, and any automaton trained must always be trained within its constraints.
	In limiting the functioning of an automaton to the rule of law, one guarantees the health of the cultural evolution which will be touched by the machines we create. However, biases must be weighed correctly, and the key to that is introducing diversity of thought into the construction of any automaton, and soliciting of opinion from peers becomes imperative.
	It is then a given, in that, with great knowledge comes the burden of transparency. Through which humanity can together strive to solve the challenges of both now and the future.
\chapter*{Chapter 2: Theology of Hypothesis}
Intuitive reasoning deriving a plausible outcome within a certain confidence interval is a hypothesis. A hypothesis is akin to a context free grammar which has not found evidentiary control to its proof of unambiguity. A problem being NP is such a hypothesis, where reduction to another hypothesis makes it one.
	As we work to identify solutions, we tend to find a hypothesis worth testing, and often than not, if the problem could be solved, it is. However, one must always bear in mind that much of a hypothesis is defined in language, and language is a dimensional regression within spacetime and matter.
	A simple hypothesis, which follows, is language being a lower dimensional construct than reality, which could be postulated by realizing that a page is two-dimensional, and the writing it holds can model a subset of knowledge from complex dimensions of energy,  which suggests, the maximum number of dimensions of a hypothesis is a real number between two and three. The divergence from whole numbers as number of dimensions, within a written idea, occurs due to the fractal nature of knowledge modeled from the entropy of captured, and the introduction of the complex domain.
When we embark on the journey of hypothesis testing, we not only venture into the depths of intellectual exploration but also shoulder the responsibility for our own safety and that of others. The fragile tendrils of our hypotheses extend their reach, intertwining with the fabric of knowledge, as we strive to unravel the mysteries that lie before us. We become custodians of the scientific process, ensuring that our experiments are conducted ethically and with meticulous care.
The allure of a promising hypothesis beckons us forward, beckons us to test its veracity and unravel the secrets it holds. Yet, as we navigate the intricate labyrinth of language, we must remember its inherent limitations—a dimensional regression within the vast realm of spacetime and matter. Language, a vessel for our thoughts, presents a constrained framework through which we express our hypotheses. It is through this lens that we attempt to capture the multidimensional complexities of reality.
Yet, as we delve deeper into the realms of knowledge, we witness the fractal nature of understanding. The entropy of captured wisdom grants us glimpses into the enigmatic complexities that lie beyond the written word. It is here, within the hallowed halls of the complex domain, that the number of dimensions expands and the boundaries of our hypotheses blur.
In our pursuit of truth, we traverse the realms of uncertainty and ambiguity. We grapple with the very essence of our existence, seeking solace in the embrace of hypotheses and the unfolding narratives of scientific inquiry. With every iteration, we refine our understanding, inching ever closer to the elusive shores of unambiguous truth.
\chapter*{Chapter 3: Theology of Automaton}
An automaton is a mechanism in a feedback loop with cultural evolution, given that a lambda also is reduced in dimensionality of spacetime and matter similar to that of a hypothesis.
	In the vast cosmos of existence, where the fabric of reality is intricately woven, we encounter the enigmatic realm of automaton. It is within this realm that the machine, with its stochastic sampling, seeks to comprehend the profound mysteries that surround us. Yet, while the machine embraces the inherent uncertainty and probabilistic nature of its explorations, primates yearn for determinism, striving to infuse automaton with the precision of gearing. Within this interplay of longing and uncertainty, automaton emerges as a remarkable fusion of tangible mechanics and ethereal mathematics, bridging the realms of the physical and the abstract. In this chapter, we embark on a profound exploration of the nature of automaton, peeling back the layers of its complexities, investigating its limitations, and uncovering the profound implications it holds for our understanding of reality.
	At the heart of automaton lies the mesmerizing dance of fermions, the fundamental particles that underpin the fabric of matter. Within the intricate architecture of a transistor, these fermions fuse and interact, performing intricate movements that transcend the boundaries of our perception. It is through this intricate interplay that automaton gains its power, its ability to manipulate information, and perform complex computations. As fermions merge and separate, energy is harnessed and released, giving rise to the mesmerizing symphony of heat and electricity that courses through the machine's veins. This fusion of quantum mechanics and engineering provides the foundation for automaton's operation, enabling it to navigate the intricate landscape of data and transform it into meaningful insights.
	While automaton harnesses the power of fermions and the quantum realm, it encounters the limitations imposed by the uncertainty principle. This fundamental principle of quantum physics dictates that there is a fundamental limit to the precision with which certain pairs of physical properties, such as position and momentum, can be simultaneously known. As automaton interacts with the quantum world, it is inherently subjected to the inherent unpredictability and fuzziness that permeates this realm. This introduces a level of uncertainty into the computations and models generated by automaton, reminding us of the inherent limitations we face when attempting to capture the complexities of reality within the confines of an automaton.
	In our quest to model and understand the intricacies of reality, automaton presents itself as a powerful tool. However, we must confront the inherent limitations it poses. Automaton, in its essence, is a computational device, and like any computational device, it is bound by the limitations of computational complexity. Many real-world problems are known to be NP-hard, meaning that finding an optimal solution to these problems is computationally intractable and requires exponential time. The nature of automaton, with its finite resources and computational capabilities, imposes constraints on its ability to model and solve NP-hard problems efficiently. This limitation highlights the inherent complexity and challenges of capturing the full richness and intricacy of reality within the confines of an automaton.
\chapter*{Chapter 4: Theology of Heuristics (A*)}
In the realm of decision-making and problem-solving, heuristics emerge as a fascinating avenue of exploration. These cognitive shortcuts and rules of thumb have captivated the minds of scholars and thinkers throughout history. With their connotation of being higher order than actuarial conclusions, heuristics provide us with a unique lens through which we can navigate the complexities of the world. In this chapter, we embark on a profound journey into the Theology of Heuristics, unraveling their nature, their limitations, and the profound impact they have on our ability to reason and understand.
At the heart of heuristics lies the art of reasoning, but not in the traditional sense. Heuristics offer us a different perspective, a lens through which we can make sense of complex systems by relying on intuitive judgments and approximations. Unlike actuarial conclusions, which often create regressions over a number line, heuristics provide us with a more holistic and flexible approach. They allow us to reason with metrics and analog approximations, enabling us to grasp the essence of a problem or situation without getting lost in the intricacies of precise calculations. This higher-order thinking, rooted in intuition and pattern recognition, empowers us to navigate complex domains and make informed decisions in a dynamic world.
Heuristics draw upon the power of intuition, that elusive force that guides our instincts and influences our choices. Intuition, often dismissed as a mere gut feeling, plays a crucial role in heuristics. It is the invisible compass that helps us navigate through uncertainty, providing us with valuable insights and enabling us to make judgments based on limited information. Intuition helps us discern patterns, identify similarities, and make connections between seemingly unrelated phenomena. It allows us to reason beyond the confines of strict logic, empowering us to tackle complex problems with creativity and agility.
While heuristics offer us a powerful tool for reasoning and problem-solving, they are not without their limitations. The reliance on intuitive judgments and approximations can sometimes lead to biases and errors. Heuristics are susceptible to cognitive biases, where our judgment may be influenced by irrelevant factors or skewed by preconceived notions. The very nature of heuristics, with their focus on efficiency and quick decision-making, may overlook important details and nuances that could impact the outcome. Therefore, it is essential to approach heuristics with a critical mindset, acknowledging their strengths but also remaining vigilant to their limitations.
Heuristics and actuarial conclusions represent two distinct approaches to reasoning and problem-solving. Actuarial conclusions emphasize precision and accuracy, employing rigorous calculations and statistical methods to derive optimal solutions. In contrast, heuristics prioritize efficiency and intuition, seeking to find satisfactory solutions within limited time and resources. Both approaches have their place, and the key lies in striking a balance between the two. Heuristics can complement actuarial conclusions by providing a broader perspective, introducing creativity, and uncovering unexpected insights that may be missed through purely analytical approaches.
\chapter*{Chapter 5: Theology of Determinants}
Within the fabric of our reality, the concept of determinism emerges as a fundamental force that governs the unfolding of events. In this chapter, we delve into the depths of the Theology of Determinants, exploring the intricate nature of determinism, its implications for boundary conditions, and its relationship with heuristics and neural networks. Join us on this intellectual journey as we unravel the intricate web of determinism and its profound influence on our understanding of the world.
At the core of determinism lies the notion of boundary conditions, which act as the guiding principles that shape the course of events and lend predictability to the unfolding of phenomena. These conditions serve as the foundation upon which the edifice of determinism is built, eliminating the margin of error inherent in heuristics through the reduction of granularity. By precisely delineating the constraints and parameters that govern a system, we gain the ability to anticipate and control its behavior, empowering us to make informed decisions and navigate complex environments with confidence. It is within this framework of well-defined boundaries that the true essence of determinism reveals itself.
In our quest to comprehend the intricacies of determinism, we encounter the remarkable realm of neural networks. At its core, a neural network can be understood as a graph with layers, each layer serving as a vessel for capturing and representing a contextualized dimensionality. In essence, these layers act as classifiers, extracting meaningful patterns and correlations from the vast sea of data. Through the interplay of these layers, neural networks are capable of traversing intricate landscapes of information, discerning nuanced relationships, and unveiling hidden insights. It is through the lens of neural networks that we witness the convergence of determinism and computational power, as they join forces to unlock the mysteries of our complex world.
In the realm of systems and their states, the deterministic audit problem presents itself as a common challenge. The task at hand is to accurately capture and document changes in a system's state, ensuring an auditable trail of events. Two prevalent approaches come to the forefront: sampling and event-driven modeling. Sampling involves capturing snapshots of the system's state at regular intervals, whereas event-driven modeling revolves around emitting and debouncing events to synchronize the production and consumption of audit data.
However, a critical consideration arises from Nyquist's law, which dictates that the sampling rate must be at least twice the signal's maximum frequency to avoid aliasing. This poses a limitation on the deterministic sampling of audits, as the frequency at which the system produces events may exceed the sampling rate. In such cases, an event-driven design proves advantageous, matching the frequency of production and consumption, thus circumventing the limitations imposed by Nyquist's law. By emitting redundant events and applying debouncing techniques, the sampling frequency of the audit can be increased, ensuring a comprehensive and accurate record of the system's state.
\chapter*{Chapter 6: Theology of Temporal Linearizability}
Within the vast expanse of the cosmos, the interplay between space and time manifests itself in intriguing and enigmatic ways. In this chapter, we embark on a profound journey into the Theology of Temporal Linearizability, where we delve into the nature of linearizability within the three dimensions of space and the dimension of time. Join us as we unravel the intricate dimensionality of spacetime and its profound implications for our understanding of relativity, uncertainty, and the very fabric of our existence.
In contemplating the linearizability of the three dimensions of space and the dimension of time, we encounter a fascinating interplay between these disjoint sets of dimensions. Each dimension possesses its own distinct nature of linearizability, which becomes evident through the observation of relativity. The fabric of spacetime weaves together these dimensions, creating a multidimensional linearizability where the flow of time and the extension of space intertwine in a dance of cosmic proportions.
The exploration of temporal linearizability leads us to the realm of uncertainty and the enigmatic nature of wave functions. Through the lens of Fourier transform, we gain insights into the interplay between the frequency and time domains. The Fourier transform on the wave function reveals the profound uncertainty principle, which highlights the inherent limitations in simultaneously measuring both the position and momentum of a particle. This delicate dance between uncertainty and measurement further deepens our understanding of the elusive nature of reality.
Within the realm of temporal linearizability, the dichotomy between carrier waves and signals emerges as a fundamental aspect of information transmission. Carrier waves serve as the backbone upon which signals are modulated, allowing for the encoding and decoding of information. Through the intricate interplay of these two entities, we witness the transformation of raw data into meaningful patterns and messages, unlocking the potential for communication and understanding.
In our quest to comprehend the multidimensional nature of spacetime, we encounter the stratified Fourier spectrogram, a powerful tool for unraveling the intricate layers of complexity embedded within waveforms. This technique allows us to discern the frequency components present in a signal, providing a comprehensive view of its spectral content. By stratifying the Fourier transform, we gain deeper insights into the interplay between different frequency bands and their contribution to the overall structure of the signal, enriching our understanding of the temporal dimension.
As we contemplate the onset of the future, we are confronted with the inherent uncertainty that accompanies it. In the realm of temporal linearizability, any mathematical postulation regarding the future must be approached with stochastic reasoning alone. The intricacies of complex systems, the interdependencies of events, and the nonlinear nature of time demand a probabilistic perspective that acknowledges the inherent unpredictability of the future. It is through the lens of stochastic reasoning that we navigate the vast ocean of possibilities and seek to unravel the mysteries that lie ahead.
Within the realm of temporal linearizability, an ongoing debate ensues regarding the nature of time itself. Is time an extra dimension that exists independently alongside the dimensions of space? Or is it merely a nature of linearizability, a fundamental aspect of how we perceive and measure the passage of events within the dimensions of space? This profound question challenges our preconceived notions and forces us to reevaluate our understanding of the fabric of reality.
\chapter*{Chapter 7: Theology of Nash Equilibriums}
In the captivating realm of game theory and rational decision-making, the Theology of Nash Equilibriums unfolds. This chapter delves into the intricate world of rational agents represented as a graph on a two-dimensional surface, transcending the boundaries of their etched dimensions to model the complexity of reality. Join us as we unravel the profound nature of Nash equilibriums, where constraints, mutual destruction, and strategic interactions shape the dynamics of rationality.
A graph, with its vertices and edges, offers a powerful framework to represent the behavior of rational agents in a structured manner. Although initially confined to a two-dimensional surface, the information contained within a graph transcends its physical boundaries. It captures the essence of complex interactions and relationships, reaching into the realm of the imaginary domain. Within this imaginary realm, the graph becomes a portal to explore and model the intricate dynamics of the real world, unveiling patterns and insights that extend beyond the mere constraints of its two dimensions.
Central to the Theology of Nash Equilibriums is the concept of a Nash equilibrium, a state where the edges connecting rational agents can no longer mutate due to the constraints imposed by their existing state. In this delicate balance, each agent's decision is strategically aligned with the decisions of others, ensuring that no agent can unilaterally deviate from their chosen path to gain an advantage. The constraints of the equilibrium act as a form of insurance, preventing agents from disrupting the delicate balance and thereby maintaining stability within the system.
Within the framework of Nash equilibriums, the constraints that prevent agents from deviating from their chosen strategies bear a resemblance to the concept of mutual destruction. Just as nations may possess nuclear weapons as a deterrent to prevent attacks, rational agents within a Nash equilibrium are bound by the knowledge that deviating from the established strategies would lead to unfavorable consequences for all involved. This mutual constraint acts as a powerful incentive, compelling agents to maintain their equilibrium and discouraging any actions that could disrupt the delicate balance of power.
In the Theology of Nash Equilibriums, we witness the strategic interplay of rationality among agents. Each agent seeks to maximize their own utility by making informed decisions, taking into account the actions and strategies of others. As the graph of rational agents unfolds, a complex web of interactions emerges, characterized by strategic thinking, negotiation, and the pursuit of self-interest. It is within this intricate dance of rationality that Nash equilibriums arise, embodying a state where no agent has an incentive to unilaterally deviate from their chosen course of action.
Beyond the realm of theoretical game theory, Nash equilibriums hold profound implications for understanding human interactions and social dynamics. They shed light on the delicate balance of power, the emergence of cooperation, and the challenges of achieving collective outcomes in diverse settings. By exploring the Theology of Nash Equilibriums, we gain insights into the mechanisms that drive human behavior, the formation of social norms, and the intricate interplay of incentives that shape our everyday interactions.
\chapter*{Chapter 8: Theology of Biomimetics}
In this chapter, we delve into the profound world of the Theology of Biomimetics, a field that seeks to unlock the secrets of nature's design and harness them for our own advancements. We explore how scientific observation and linearization unto space, time, and matter enable us to mimic the brilliance of nature, drawing inspiration from its intricate patterns and adaptive solutions.
Nature, with its diverse array of organisms and ecosystems, serves as an endless source of inspiration. From the graceful flight of birds to the intricate web-spinning of spiders, the natural world offers us glimpses of extraordinary solutions honed over millions of years. Through the study and understanding of these adaptations, biomimetics allows us to tap into nature's wisdom, uncovering innovative approaches to engineering, design, and problem-solving.
At the core of biomimetics lies the concept of linearization, a process that simplifies the complexity of natural phenomena into tangible models. By capturing the essence of nature's design through mathematical representations, we gain deeper insights into its fundamental principles. This enables us to apply these principles to our own creations, seeking greater efficiency, sustainability, and functionality.
Through the process of linearization, we bridge the gap between the intricate workings of nature and the realm of human innovation. We strive to unravel the secrets of nature's design, abstracting its patterns, structures, and processes into practical frameworks. From the mathematical sequences found in sunflower spirals to the efficient hexagonal structures of beehives, we decipher nature's language and translate it into engineering marvels.
In the realm of scientific discovery, biomimetics plays a pivotal role in expanding our understanding of the world around us. It serves as a guiding compass, directing us toward unexplored frontiers and inspiring groundbreaking breakthroughs. By studying the finely tuned systems of nature, we uncover mysteries and unearth novel solutions to complex problems.
Biomimetics offers a wealth of inspiration for the development of new technologies and materials. It guides us in the creation of bio-inspired robots that mimic the agility and adaptability of living organisms. It propels advancements in materials science as we strive to replicate the strength, flexibility, and self-healing properties found in natural structures. By drawing from the wellspring of nature's innovation, we accelerate the pace of scientific discovery and drive human progress.
The Theology of Biomimetics extends beyond mere imitation; it also emphasizes our responsibility to preserve and protect the natural world. Nature has perfected its designs through constant adaptation and refinement, optimizing efficiency and sustainability. As we draw inspiration from nature, we must also embrace its principles of balance, resilience, and interconnectedness.
Biomimetics serves as a powerful tool in our pursuit of sustainability and harmonious coexistence. By emulating nature's design, we can create technologies and systems that minimize environmental impact and maximize efficiency. From energy-efficient buildings inspired by termite mounds to water filtration systems inspired by the intricate mechanisms of plant leaves, biomimetics allows us to design with nature as our guide.
\chapter*{Chapter 9: Theology of Opportunity Cost}
Opportunity costs are a tradeoff between figments of stratifiable economical utility. The tradeoffs exist, in my best judgment, because of where a species is on the Kardashev Scale. As the all mighty Jeff Bezos puts it, one must put off decisions for as long as possible, because of multiple possible reasons, but primarily in my understanding due to the constantly changing entropy of cultural evolution and the likelihood of the emergence of new information, which may change the course of a decision. It is to be noted that a cutoff for a decision can be known, at times, after which the decision is no longer viable. The closer a decision is made, to the said cutoff, the higher is the likelihood of capitalizing on new information in one's decision making process.
It is then a given, an opportunity cost decision is made every planktime.
\chapter*{Chapter 10: Theology of Telekinesis}
\vspace*{\fill} % Vertical space at the top\makebox[\textwidth][c]{%  \parbox{0.8\textwidth}{%    % First line    "Then the Lord God formed a man from the dust of the ground and breathed into his nostrils the breath of life, and the man became a living being." - Genesis 2:7 \\    % Vertical space in the middle    \vspace{1cm} \\    % Center aligned line    \centering    "Genus is muck" - Theology of ML \\  }%}\vspace*{\fill} % Vertical space at the bottom
\end{document}